# 第七章 并行数据处理与性能

[TOC]

## 并行流

<u>并行流</u>就是一个把内容分成多个数据块，并用不同的线程分别处理多个数据块的流。

假设你需要写一个方法，接收数字`n`为参数，并返回从1到给定参数的所有数字的和。一个直接的方法是生成一个无限大的流：

```java
public static long sequentialSum(long n) {
    return Stream.iterate(1L,i->i+1)
        limit(n).reduce(0L,Long::sum);
}
```

### 将顺序流转换为并行流

对顺序流可以使用`parallel()`可以把顺序流转换为并行流：

```java
public static long parallelSum(long n){
    return Stream.iterate(1L,i->i+1)
        		.limit(n)
        		.parallel()			// 将顺序流转换为并行流
        		.reduce(0L,Long::sum);
}
```

![](https://zhangzhaolin.oss-cn-beijing.aliyuncs.com/TIM%E6%88%AA%E5%9B%BE20190306145606.png)

🔺 **对顺序流调用`parallel`方法并不意味着流本身有任何实际的变化。它在内部实际上就是设置了一个`boolean`标志，表示你想让调用`parallel`之后进行的所有操作都并行执行**

类似的，**对并行流使用`sequential`方法就可以把它变成顺序流**，例如你可以这样做 ：

```java
stream.parallel().filter(...)
    .sequential()
    .map(...)
    .parallel()
    .reduce(...);
```

在上述代码中，流水线会并行执行。

### 测量流性能

测量对前`n`个自然数求和的函数 ：

```java
private static long measureSumPerf(Function<Long, Long> function, long n) {
    long fastest = Long.MAX_VALUE;
    for (int i = 0;i<20;i++){
        long start = System.nanoTime();
        function.apply(n);
        long duration = (System.nanoTime() - start) / 1_000_000;
        if (duration < fastest) fastest = duration;
    }
    return fastest;
}
```

测试求和函数性能 ：

```java
System.out.println("sequentialSum : " + measureSumPerf(ParallelStream::sequentialSum));
System.out.println("parallelSum : " + measureSumPerf(ParallelStream::parallelSum));
```

我们打印之后发现，求和方法的并行版本要比顺序执行版本慢得多，这里实际上有两个问题 ：

- `iterate`生成的是装箱对象，必须拆箱成数字才能求和
- 我们很难把`iterate`分成多个独立的块来并行执行

`iterate`很难分割成能够独立执行的小块，因为每次应用这个函数都要依靠前一次应用的结果 ：

![](https://zhangzhaolin.oss-cn-beijing.aliyuncs.com/2019-3-6/20190306153731.png)

### 使用更为有效的方法

`LongStream.rangeClosed`方法与`iterate`相对比有两个优点 ：

- `LongStream.rangeClosed`直接产生原始类型的`long`，没有装箱拆箱的开销
- `LongStream.rangeClosed`会产生数值范围，很容易拆分为独立的小块。

用于顺序流上的性能 ：

```java
private static long sequentialSum(long n) {
    return LongStream.rangeClosed(1, n)
            .limit(n)
            .reduce(0L, Long::sum);
}
```

```java
System.out.println
("流方法 ：" + measureSumPerf(ParallelStream::sequentialSum, 10_000_000));
```

结果为 ：

> 流方法 ：22

并行流上的性能 ：

```java
private static long parallelSum(long n) {
    return LongStream.rangeClosed(1, n)
            .parallel()
            .limit(n)
            .reduce(0L, Long::sum);
}
```

```java
System.out.println
("并行流方法 ：" + measureSumPerf(ParallelStream::parallelSum, 10_000_000));
```

结果为 ：

> 并行流方法 ： 1

### 🎂 高效使用并行流

- 如果有疑问，测量。在考虑选择顺序流还是并行流时，第一个也是最重要的建议就是用适当的基准来检查其性能。
- 留意装箱。自动装箱和拆箱会大大降低性能。Java8中有<u>原始类型流</u>（`IntStream`、`LongStream`、`DoubleStream`）来避免这种操作。
- 有些操作本身在并行流上的性能就比顺序流差。特别是`limit`和`findFirst`等**依赖于元素顺序的操作**，他们在并行流上执行的代价非常大。例如，`findAny`要比`findFirst`性能好，因为`findAny`不按照顺序来执行。**调用`unordered`方法可以将有序流转换为无序流**，对无序流调用`limit`方法可能会比单个有序流更高效。
- 对于较小的数据量，选择并行流几乎从来都不是一个好的决定
- 需要考虑流背后的数据结构是否易于分解。例如，`ArrayList`的拆分效率比`LinkedList`高很多，因为前者不需要遍历就可以平均拆分，而后者必须要遍历。
- **流自身的特点、以及流水线的中间操作修改流的方式，都可能会改变分解过程的性能。**例如，一个`SIZED`流（该`Spliterator`由一个已知大小的源建立（例如Set），因此`estimatedSize()`返回的是准确值）可以分成大小相等的两个部分，这样每一部分都可以比较高效的并行处理，但是筛选操作可能丢弃的元素个数无法预测，导致流本身大小未知。
- 考虑终端操作中合并步骤的代价是大是小（例如`Collector`中的`combiner`方法）。如果这一步代价很大，那么组合每个子流产生的部分结果所付出的代价就可能超过并行流得到的性能提升。

|         源          | 可分解性 |
| :-----------------: | :------: |
|     `ArrayList`     |   极佳   |
|    `LinkedList`     |    差    |
| `IntStream.range()` |   极佳   |
|  `Stream.iterate`   |    差    |
|      `HashSet`      |    好    |
|      `TreeSet`      |    好    |

## 分支/合并框架

分支/合并框架使用的目的就是<u>以递归的方式将可以并行的任务拆分成为更小的任务，然后将每一个子任务的结果合并起来形成整体结果</u>。它是`ExecutorService`接口的一个实现，它把子任务分配给线程池（称之为`ForkJoinPool`）中的工作线程。

### 使用`RecursiveTask`

要把任务提交到`ForkJoinPool`线程池，必须要创建一个`RecursiveTask<R>`的子类，其中`R`是并行化任务（以及所有子任务）产生的结果类型，或者如果任务不返回结果，则是创建一个`RecursiveAction`的子类。

要定义`RecursiveTask`，只需要实现它唯一的抽象方法`compute`：

```java
protected abstract V compute();
```

这个方法同时定义了将任务拆分成子任务的l逻辑，以及无法再拆分或者不方便拆分时，生成单个子任务结果的逻辑。

```
if(任务足够小或者不可分){
    顺序计算该任务
}else{
    将任务分成两个子任务
    递归调用本方法，拆分每一个子任务，等待所有子任务完成
    合并每一个子任务的结果
}
```

递归的任务拆分过程如图所示 ：

![](https://zhangzhaolin.oss-cn-beijing.aliyuncs.com/2019-3-6/20190306173419.png)

使用分支/合并框架执行并行求和 ：

```java
import java.util.concurrent.RecursiveTask;

public class ForkJoinSumCalculator extends RecursiveTask<Long> {
	// 要求和的数组
    private final long[] numbers;
    private final int start;
    private final int end;
	// 不再将任务分解为子任务的数组大小
    private final int THRESHOLD = 10_000;

    public ForkJoinSumCalculator(long[] numbers){
        this(numbers,0,numbers.length);
    }

    private ForkJoinSumCalculator(long[] numbers,int start,int end){
        this.numbers = numbers;
        this.start = start;
        this.end = end;
    }
	// 覆盖RecursiveTask抽象方法
    @Override
    protected Long compute() {
        int length = end - start;
        // 如果大小小于或者等于阈值，则直接计算结果
        if (length <= THRESHOLD){
            return computeCalculation();
        }
        ForkJoinSumCalculator leftTask 
            = new ForkJoinSumCalculator(numbers,start,start + length/2);
        ForkJoinSumCalculator rightTask 
            = new ForkJoinSumCalculator(numbers,start+length/2,end);
        // 利用另外一个ForkJoinPool线程异步执行新创建的子任务
        rightTask.fork();
        // 同步执行第二个子任务，有可能允许进一步递归划分
        long leftResult = leftTask.compute();
        // join() : 读取第一个子任务的结果，如果尚未完成就等待
        return leftResult + rightTask.join();
    }

    private Long computeCalculation(){
        long sum = 0L;
        for (int i = start;i < end ; i++){
            sum += numbers[i];
        }
        return sum;
    }
}
```

```java
public static long forkJoinSum(long n) {
    long[] numbers = LongStream.rangeClosed(1, n).toArray();
    return new ForkJoinPool().invoke(new ForkJoinSumCalculator(numbers));
}
```

**请注意在实际应用中，使用多个`ForkJoinPool`是没有实际意义的。出于这个原因，一般来说把它实例化一次，然后把实例保存在静态字段中，使之成为单例。**

### 使用分支/合并的最佳做法

- 对一个任务调用`join`方法会阻塞调用方，直到该任务做出结果。因此，有必要在两个子任务的计算都开始之后再调用它。
- 不应该在`RecursiveTask`内部调用`ForkJoinPool`的`invoke`方法。相反，你应该始终直接调用`compute`或者`fork`方法，只有顺序代码才应该用`invoke`来启动并计算。
- 对子任务调用`fork`方法可以把它排进`ForkJoinPool`。同时对左边和右边子任务同时调用`fork`似乎很自然，**但是这样做的效率要比直接对其中一个调用`compute`低**。这样做你可以为其中一个子任务重用同一个线程，从而避免在线程池中多分配一个任务造成的开销。
- 和并行流一样，你不应该理所应当的认为在多线程处理器上使用分支/合并框架就比顺序计算快。

### 工作窃取

在实际中，每一个子任务所花的时间可能天差地别，要么是因为划分策略效率低，要么是有不可知的原因。

分支/合并框架使用一种被称为<u>工作窃取</u>的技术来解决这个问题，这些任务被平均分配到`ForkJoinPool`中的所有线程上。每个线程都为分配给它的任务保存一个双项链式队列，每完成一个任务，就会从队列头上取出下一个任务开始执行。基于前面所描述的原因，某一个线程可能早早的完成了分配给它的所有任务，也就是它的任务已经空了，而其他的任务还很忙。这是，这个线程并没有闲下来，而是随机选取了一个别的线程，从队列的尾巴上”偷走”一个任务。这个过程一直继续下去，直到所有的任务都执行完毕，所有的队列都清空。

![](https://zhangzhaolin.oss-cn-beijing.aliyuncs.com/2019-3-13/20190313150735.png)

## `Spliterator`

和`Iterator`一样，`Spliterator`也可以用于遍历数据源中的元素，但是它是为了并行执行而设置的。

```java
public interface Spliterator<T> {
	boolean tryAdvance(Consumer<? super T> action);
    Spliterator<T> trySplit();
    long estimateSize();
    int characteristics();
}
```

`T`是`Spliterator`遍历的元素类型。

- `tryAdvance`方法类似于普通的`Iterator`，因为它会按顺序一个个使用`Spliterator`中的元素，如果还有其他元素要遍历就返回`true`
- `trySplit`是专为`Spliterator`接口设计的，因为它可以把一些元素划分出去给第二个`Spliterator`，让他们两个并行处理
- `estimateSize`方法估计还剩下多少元素要遍历

### 拆分过程

![](https://zhangzhaolin.oss-cn-beijing.aliyuncs.com/2019-3-13/20190313154802.png)

### `Spliterator`特性

|     特性     |                             含义                             |
| :----------: | :----------------------------------------------------------: |
|  `ORDERED`   | 元素有既定的顺序（例如`List`），因此`Spliterator`在遍历和划分时也会遵循这一顺序 |
|  `DISTINCT`  |    对于任意一对遍历过的元素X和Y，`x.equals(y)`返回`false`    |
|   `SORTED`   |               遍历的元素按照一个预定的顺序排序               |
|   `SIZED`    | 该`Spliterator`由已知大小的源建立（例如`Set`），因此`estimatedSize()`返回的是准确值 |
|  `NONNULL`   |                    保证遍历的元素不为NULL                    |
| `IMMUTABLE`  | `Spliterator`的数据源不能修改。这意味着在遍历时不能添加、删除或者修改任何元素 |
| `CONCURRENT` |   该`Spliterator`的数据源可以被其他线程同时修改而无需同步    |
|  `SUBSIZED`  | 该`Spliterator`和所有从它拆分出来的`Spliterator`都是`SIZED`  |

### 实现自己的`Spliterator`

首先用一个简单的方法来统计`String`中单词的个数 ：

```java
private static int countWordsIteratively(String s) {
    int counter = 0;
    // 保存上一个字符是否是空格
    boolean isWhiteSpace = true;
    for (char c : s.toCharArray()){
        if (Character.isWhitespace(c)){
            isWhiteSpace = true;
        }else{
            // 当上一个字符是空格 这一个字符不是空格时 计数器加一
            if (isWhiteSpace) counter++;
            isWhiteSpace = false;
        }
    }
    return counter;
}
```

测试一下这个代码 ：

```java
System.out.println(countWordsIteratively(SENTENCE));
```

> 19

### 以函数式风格重写单词计数器

首先，需要将`String`转换为一个流：

```java
Stream<Character> characterStream = IntStream.range(0,SENTENCE.length()).mapToObj(SENTENCE::charAt);
```

现在，你可以用这个流来做规约来计算字数，但是，在规约流时候，你需要两个状态：统计字数、上一个字符是否是空格。

```java
public class WordCounter {
    private final int counter;
    private final boolean isWhiteSpace;
    public WordCounter(int counter, boolean isWhiteSpace) {
        this.counter = counter;
        this.isWhiteSpace = isWhiteSpace;
    }
    // 和迭算法一样，accumulator方法一个个遍历Character
    public WordCounter accumulator(Character character){
        if (Character.isWhitespace(character)){
            return isWhiteSpace ? this : new WordCounter(counter,true);
        }else{
            // 上一个字符是空格，这一个字符不是空格时 单词计数器加一
            return isWhiteSpace ? new WordCounter(counter+1,false) : this;
        }
    }
    public WordCounter combiner(WordCounter wordCounter){
        return new WordCounter(counter + wordCounter.counter,false);
    }
    public int getCounter(){
        return counter;
    }
}
```

![](https://zhangzhaolin.oss-cn-beijing.aliyuncs.com/2019-3-13/20190313172347.png)

现在，写一个方法规约`Character`流 ：

```java
private static int countWords(Stream<Character> characterStream){
    return characterStream.reduce(new WordCounter(0,true)
            ,WordCounter::accumulator,WordCounter::combiner).getCounter();
}
System.out.println(countWords(characterStream));
```

如果尝试着将使用并行流加快字数统计：

```java
System.out.println(countWords(characterStream.parallel()));
// 27
```

这样直接并行是不正确的。因为原始的`String`在任意位置拆分，所以有时候一个词会变成两个词，然后数了两次。这就说明，拆分流可能会影响结果。

解决方案就是要确保String不是在随机位置拆分的，而只能在词尾拆开。要做到这一点，你必须为`Character`实现一个`Spliterator`，它只能在两个单词之间拆分`String`：

```java
import java.util.Spliterator;
import java.util.function.Consumer;

public class WordCounterSpliterator implements Spliterator<Character>{

    private final String string;
    private int currentChar;

    public WordCounterSpliterator(String string) {
        this.string = string;
    }

    @Override
    public boolean tryAdvance(Consumer<? super Character> action) {
        // 处理当前字符
        action.accept(string.charAt(currentChar++));
        // 如果还有字符处理，则返回true
        return currentChar < string.length();
    }

    @Override
    public Spliterator<Character> trySplit() {
        int currentLength = string.length() - currentChar;
        if (currentLength <= 10){
            // 返回null表示要解析的String已经足够小，可以顺序处理
            return null;
        }
        // 将试探拆分位置 设置在要解析的String的中间
        for (int splitPos = currentLength/2 + currentChar;splitPos<string.length();splitPos++){
            // 让拆分位置前进到下一个空格
            if (Character.isWhitespace(string.charAt(splitPos))){
				// 创建一个新的Spliteraotr来解析String从开始到拆分位置的部分
                Spliterator<Character> spliterator = new WordCounterSpliterator(string.substring(currentChar,splitPos));
                // 将这一个Spliterator的开始位置设置为拆分位置
                currentChar = splitPos;
                return spliterator;
            }
        }
        return null;
    }

    @Override
    public long estimateSize() {
        return string.length() - currentChar;
    }

    @Override
    public int characteristics() {
        return ORDERED + SIZED + IMMUTABLE + NONNULL + SUBSIZED;
    }
}
```

![](https://zhangzhaolin.oss-cn-beijing.aliyuncs.com/2019-3-14/绘图1.jpg)

- `tryAdvance`方法把`String`中当前位置的`Character`传给了`Consumer`，并让位置加一。`Consumer`是一个Java内部类，在遍历流时，将要处理的`Character`传给了一系列要对其执行的函数。在这个例子中，只有一个规约函数，即`WordCounter`的`accumulate`方法。如果新的指针位置小于`String`总长，且还有要遍历的`Character`，则`tryAdvance`返回`true`
- `trySplit`定义了拆分要遍历的数据结构的逻辑。就像`RecursiveTask`中的`compute`方法一样，**首先要设定一个不再继续拆分的下限**。在实际应用中，就像`fork-join`那样，你肯定需要更高的下限来避免生成太多的任务。如果剩余的`Character`数量低于下限，你就返回`null`表示无需进一步拆分。相反，如果你需要执行拆分，**就把试探的拆分位置设在要解析的`String`块中间。但是我们没有直接使用这个拆分位置，因为要避免把词在中间断开**，于是继续往前找，**一直到找到一个空格**。**一旦找到了适当的拆分位置，就可以创建一个新的`Spliterator`来遍历从当前位置到拆分位置的字串**；把当前位置this设置为拆分位置，因为之前的部分将由新的`Spliterator`来处理，最后返回。
- 还需要遍历的元素的长度`estimatedSize`就是这个字符串长度减去当前遍历的位置差
- 最后，`characteristics`方法告诉框架这个`Spliterator`是`ORDERED`（顺序就是`String`中各个`Character`的次序）、`SIZED`（`estimatedSize`方法的返回值是精确的）、`SUBSIZED`（`trySplit`方法创建的其他`Spliterator`也有确切的大小）、`NONNULL`（`String`中不能有空的`Character`）和`IMMUTABLE`（在解析`String`时不能再添加`Character`）。

```java
Spliterator<Character> spliterator = new WordCounterSpliterator(SENTENCE);
// 传给StreaSuppot.stream的第二个参数意味着你想创建一个并行流
Stream<Character> stream = StreamSupport.stream(spliterator, true);
System.out.println(countWords(stream));
```

❄ `Spliterator`可以在第一次遍历、第一次拆分或者第一次查询估计大小时绑定元素的数据源，而不是在创建时就绑定。这种情况下，它被称之为<u>延迟绑定的</u>`Spliterator`

## 🐥 小记

- 内部迭代让你可以并行处理一个流，而无需在代码中显示使用和协调不同的线程。
- 虽然并行处理一个流很容易，却不能保证程序在所有情况下都运行得很快。并行软件行为和性能有时是违反直觉的，因此一定要测量，确保你没有把程序拖得很慢。
- 像并行流那样对一个数据集并行执行操作可以提升性能，特别是要处理的元素数量庞大，或处理单个元素特别耗时的时候。
- 从性能角度上看，使用正确的数据结构，如尽可能利用原始流而不是一般化的流，几乎总是比尝试并行化某些操作更为重要。
- 分支/合并框架让你得以用递归的方式将可以并行的任务拆分成更小的任务，在不同的线程上执行，然后将各个子任务合并起来生成整个结果
- `Spliterator`定义了并行流如何拆分它要遍历的数据